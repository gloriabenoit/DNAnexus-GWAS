{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Overview This tutorial provides a step-by-step guide on the use of DNAnexus to perform a GWAS on the UK Biobank data. We will run everything from the command line, but will monitor our jobs on the project's web page. This tutorial assumes that you already have a researcher account on the UKBiobank site, and have access to a DNAnexus project. If not, please create an account here , and once it has been validated, create an account on UKB-RAP with your UK Biobank credentials to access DNAnexus. We will see both the use of PLINK2 and regenie in order to perform a basic GWAS using whole genome sequences for chromosome 1 to 22. In order to parallelize the analyses, we will perform 22 different GWAS, one for each chromosome, and combine the results locally. Requirements To follow this tutorial, you will need Python 3 . Final architecture At the end of this tutorial, your DNAnexus project's architecture should look like this: \u251c\u2500\u2500 app-id \u251c\u2500\u2500 app-id.dataset \u251c\u2500\u2500 Bulk \u251c\u2500\u2500 metadata \u251c\u2500\u2500 Showcase \u2514\u2500\u2500 WKD_<your-name> \u251c\u2500\u2500 covariates.txt \u251c\u2500\u2500 plink_BMI.txt \u251c\u2500\u2500 plink_gwas_BMI \u251c\u2500\u2500 regenie_BMI.txt \u251c\u2500\u2500 regenie_gwas_BMI \u2502 \u251c\u2500\u2500 merge \u2502 \u2514\u2500\u2500 QC_lists \u2514\u2500\u2500 white_british.txt This will vary based on whether you use both PLINK2 and regenie, or only one, and if you have changed files/repertory names. Please note, if modified, files and repertory names have to be the same across all commands.","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#overview","text":"This tutorial provides a step-by-step guide on the use of DNAnexus to perform a GWAS on the UK Biobank data. We will run everything from the command line, but will monitor our jobs on the project's web page. This tutorial assumes that you already have a researcher account on the UKBiobank site, and have access to a DNAnexus project. If not, please create an account here , and once it has been validated, create an account on UKB-RAP with your UK Biobank credentials to access DNAnexus. We will see both the use of PLINK2 and regenie in order to perform a basic GWAS using whole genome sequences for chromosome 1 to 22. In order to parallelize the analyses, we will perform 22 different GWAS, one for each chromosome, and combine the results locally.","title":"Overview"},{"location":"#requirements","text":"To follow this tutorial, you will need Python 3 .","title":"Requirements"},{"location":"#final-architecture","text":"At the end of this tutorial, your DNAnexus project's architecture should look like this: \u251c\u2500\u2500 app-id \u251c\u2500\u2500 app-id.dataset \u251c\u2500\u2500 Bulk \u251c\u2500\u2500 metadata \u251c\u2500\u2500 Showcase \u2514\u2500\u2500 WKD_<your-name> \u251c\u2500\u2500 covariates.txt \u251c\u2500\u2500 plink_BMI.txt \u251c\u2500\u2500 plink_gwas_BMI \u251c\u2500\u2500 regenie_BMI.txt \u251c\u2500\u2500 regenie_gwas_BMI \u2502 \u251c\u2500\u2500 merge \u2502 \u2514\u2500\u2500 QC_lists \u2514\u2500\u2500 white_british.txt This will vary based on whether you use both PLINK2 and regenie, or only one, and if you have changed files/repertory names. Please note, if modified, files and repertory names have to be the same across all commands.","title":"Final architecture"},{"location":"errors/","text":"Errors when running jobs A job running on DNAnexus has 4 outcomes: Done: The job was successful. Failed: Out of Memory Failed: Low disk space Failed: Terminated by the cloud provider (only for low priority jobs) We will take you through all 3 failed outcomes, and what you can do to avoid them. Out of memory If the cause of failure is the following: Error while running the command (please refer to the job log for more information). Warning: Out of memory error occurred during this job. You need to choose an instance with a bigger memory. The memory infix in the instance is mem . For more information on instances, check the official doc on instance types . Low disk space If the cause of failure is the following: Error while running the command (please refer to the job log for more information). Warning: Low disk space during this job. You need to choose an instance with a bigger storage. The storage infix in the instance is ssd or hdd . For more information on instances, check the official doc on instance types . Interruption limit Jobs with a low priority can be interrupted if its ressources can be used for a high priority jobs. A low priority job can be interrupted at most 10 times, then it will result in the following error: The machine running the job was terminated by the cloud provider You simply need to restart your job, either on the same instance or another one, if the one used is too popular.","title":"Errors when running jobs"},{"location":"errors/#errors-when-running-jobs","text":"A job running on DNAnexus has 4 outcomes: Done: The job was successful. Failed: Out of Memory Failed: Low disk space Failed: Terminated by the cloud provider (only for low priority jobs) We will take you through all 3 failed outcomes, and what you can do to avoid them.","title":"Errors when running jobs"},{"location":"errors/#out-of-memory","text":"If the cause of failure is the following: Error while running the command (please refer to the job log for more information). Warning: Out of memory error occurred during this job. You need to choose an instance with a bigger memory. The memory infix in the instance is mem . For more information on instances, check the official doc on instance types .","title":"Out of memory"},{"location":"errors/#low-disk-space","text":"If the cause of failure is the following: Error while running the command (please refer to the job log for more information). Warning: Low disk space during this job. You need to choose an instance with a bigger storage. The storage infix in the instance is ssd or hdd . For more information on instances, check the official doc on instance types .","title":"Low disk space"},{"location":"errors/#interruption-limit","text":"Jobs with a low priority can be interrupted if its ressources can be used for a high priority jobs. A low priority job can be interrupted at most 10 times, then it will result in the following error: The machine running the job was terminated by the cloud provider You simply need to restart your job, either on the same instance or another one, if the one used is too popular.","title":"Interruption limit"},{"location":"input/","text":"Input files Genetic data On DNAnexus, whole genome sequences data are saved in multiple formats: BGEN format ( .bgen and .sample ), PLINK format ( .bed , .bim and .fam ) or pVCF format ( .vcf.gz.tbi ), among others. For more information on the data available, you can run the following command: dx ls \"/Bulk/Whole genome sequences\" On DNAnexus, when a job is executed, a worker is spun up in the cloud, then the job's code and inputs are downloaded to that worker and exectuted. This is the standard behavior, but inputs can also be mounted to avoid their downloading costs. PLINK2 PLINK2 can read both BGEN and PLINK format. Therefore, we have 4 ways of inputing genetic data: File format Mounted BGEN No BGEN Yes PLINK No PLINK Yes After some trial and error, we have found that using the BGEN format without mounting it was the quickest way to perform a GWAS using PLINK2. Downloading and translating BGEN files locally was quicker than downloading or mounting the PLINK files. Therefore, in this tutorial, we will input BGEN files directly. The path to the genetic data is the following: \"/Bulk/Whole genome sequences/Population level genome variants, BGEN format - interim 200k release/\" . Additionnal data In order to run our GWAS, apart from the genetic and sample data, we need 3 additionnal files: The phenotype (for instance, BMI) The ids of individuals we wish to keep (for instance, white british) The covariates to use (for instance, 18 genetic principal components, the sex and the age) Theses files can either be uploaded directly to your projects using dx upload , or created using DNAnexus data. This tutorial will guide you through the second option. All three files will be uploaded to your current dx repertory ( WKD_<your-name> if you are closely following this tutorial). If you want to upload them somewhere else, you can either move directory with dx cd before uploading, or use the --path or --destination option to specify the DNAnexus path to upload the files. Phenotype To extract the phenotype that we want, we first need to download all available data-fields in our dataset. You will need the record-id , which is the id of the .dataset file at the root of your DNAnexus project. On your project's web page, you can find the id by selecting the .dataset file and searching for the ID in the info panel that appears on the right. Please note, when running the extract_dataset command you might encounter a ('Invalid JSON received from server', 200) error. If this happens, you simply need to rerun the code. dx extract_dataset <record-id> -ddd --delimiter \",\" This command will output 3 files: <app-id>.data_dictionary.csv contains a table with participants as the rows and metadata along the columns, including field names (see table below for naming convention) <app-id>.codings.csv contains a lookup table for the different medical codes, including ICD-10 codes that will be displayed in the diagnosis field column (p41270) <app-id>.entity_dictionary.csv contains the different entities that can be queried, where participant is the main entity that corresponds to most phenotype fields To make it easier, you can rename theses files to a shorter name like ukbb . rename <app-id> ukbb app* We first need to get the field name of the phenotype(s) we want to extract. As an example, we will extract the BMI index ( 21001 ), but you can extract any number of phenotypes. For the main participant phenotype entity, the Research Analysis Platform (UKB-RAP) uses field names with the following convention: Type of field Syntax for field name Example Neither instanced nor arrayed p<FIELD> p31 Instanced but not arrayed p<FIELD>_i<INSTANCE> p40005_i0 Arrayed but not instanced p<FIELD>_a<ARRAY> p41262_a0 Instanced and arrayed p<FIELD>_i<INSTANCE>_a<ARRAY> p93_i0_a0 This means one phenotype ID can actually have multiple data field. For example, BMI has four instances. The following python script will extract the phenotype that you wish, and every array or instance associated. It will ouptput pheno_extract.csv which contains individual ids and any phenotype you chose to extract. \"\"\" Extract phenotype(s) from UKBB based on field ID(s). \"\"\" import os import subprocess import pandas as pd # Input FILENAME = \"ukbb.dataset.data_dictionary.csv\" OUTPUT = \"pheno_extract.csv\" DATASET = \"<record-id>\" FIELD_ID = [21001] # BMI id def field_names_for_ids(filename, field_ids): \"\"\" Converts data-field id to corresponding field name. Parameters ---------- filename : str Path to the '.dataset.data_dictionary.csv' file. field_ids : list All field ids. data.frame (pandas) Projects's .data_dictionary.csv file. Returns ------- list All corresponding field names. \"\"\" data = pd.read_csv(filename, sep=',') field_names = [\"eid\"] for _id in field_ids: select = list(data[data.name.str.match(r'^p{}(_i\\d+)?(_a\\d+)?$'.format(_id))].name.values) field_names += select field_names = [f\"participant.{f}\" for f in field_names] return field_names # Convert id to names FIELD_NAMES = field_names_for_ids(FILENAME, FIELD_ID) FIELD_NAMES = \",\".join(FIELD_NAMES) # Extract phenotype(s) if os.path.exists(OUTPUT): os.remove(OUTPUT) cmd = [\"dx\", \"extract_dataset\", DATASET, \"--fields\", FIELD_NAMES, \"--delimiter\", \",\", \"--output\", OUTPUT] subprocess.check_call(cmd) Please be aware, since extract_dataset has no overwite option by design, we implemented ourselves. Running the previous code will first delete pheno_extract.csv if it's present, allowing for the extraction to happen. PLINK and regenie use the same formatting for the phenotype file, with a single exception : the code for missing values. Apart from this, both need to duplicate the individuals ids and only keep the first instance for our phenotype. More information on phenotype files formatting can be found here for PLINK2 and here for regenie. \"\"\" Format phenotype file. \"\"\" import pandas as pd # Input FILENAME = \"pheno_extract.csv\" PHENOTYPE = \"BMI\" SOFTWARE = 'p' # for PLINK2 or 'r' for regenie. def format_phenotype(filename, phenotype, software): \"\"\" Save phenotype according to software format. Parameters ---------- filename : str Phenotype file to format. phenotype : str Phenotype name. format : str { 'p', 'r'} Either 'p' for PLINK2 or 'r' for regenie, to correctly format the file. \"\"\" # Software specific format. if software == 'p': na_val = -9 output = f\"plink_{phenotype}.txt\" elif software == 'r': na_val = 'NA' output = f\"regenie_{phenotype}.txt\" # Data data = pd.read_csv(filename, sep=',') # To be changed accordingly pheno = data.iloc[:,[0,1]] pheno = pheno.rename(columns={pheno.columns[0]: \"IID\", pheno.columns[1]: phenotype}) data = data.rename(columns={data.columns[0]: \"FID\"}) merged = pd.concat([data.iloc[:, 0], pheno], axis=1) # Save output merged.to_csv(output, sep='\\t', index=False, header=True, na_rep=na_val) # Save phenotype format_phenotype(FILENAME, PHENOTYPE, SOFTWARE) You can modify the format_phenotype function to your heart's desire, depending on what you wish to do with the phenotypes. This is only a suggestion, and might not work for more specific phenotypes. You can now upload the formated phenotype file. dx upload plink_BMI.txt dx upload regenie_BMI.txt For the sake of this tutorial, we upload two files: one for each type of formatting. Individual ids Running a GWAS on a specific population helps reduce the bias caused by population stratification. It is therefore an important step. To filter out individuals based on their ethnic background, we can use the phenotype extraction script and the data-field 21000 . You simply need to replace the following line: FIELD_ID = [21000] # ethnic background id This field uses the 1001 data encoding . In this code, 1001 means white british which is the main ethnic group, and the one we want to select. pop_code=1001 pop_name=\"white_british\" population=\"pheno_extract.csv\" awk -F \",\" -v var=\"$pop_code\" '$2~var{print $1,$1}' $population > $pop_name.txt This code will output the file white_british.txt , containing the ids of the individuals of the white british ethnic background. You can now upload the ids of your individuals. dx upload white_british.txt Covariates The genetic principal components from the UKBB individuals are stored in the 22009 data field. We could use our phenotype extraction algorithm, but for some reason, it is not working. Therefore, we will use another script. We will use 20 variables as covariates: the first 18 PCA components, the sex ( 31 ) and the age ( 21003 ) of individuals. However, you can extract whatever you want as covariates. More information on covariates files formatting can be found here for PLINK2 and here for regenie. record_id=\"<record-id>\" field_names=\"participant.eid,participant.eid,\" for i in {1..18} do field_names+=\"participant.p22009_a$i,\" done field_names+=\"participant.p31,participant.p21003_i0\" # Sex and age dx extract_dataset $record_id --fields $field_names --delimiter \",\" --output covariates.txt echo -e \"FID,IID,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,PC17,PC18,Sex,Age\" > file.tmp tail -n+2 covariates.txt >> file.tmp awk -F , '$3!=\"\"' file.tmp > covariates.txt # Remove ind with no PC data sed 's/,/\\t/g' covariates.txt > file.tmp mv file.tmp covariates.txt You can now upload the covariates file. dx upload covariates.txt","title":"Input files"},{"location":"input/#input-files","text":"","title":"Input files"},{"location":"input/#genetic-data","text":"On DNAnexus, whole genome sequences data are saved in multiple formats: BGEN format ( .bgen and .sample ), PLINK format ( .bed , .bim and .fam ) or pVCF format ( .vcf.gz.tbi ), among others. For more information on the data available, you can run the following command: dx ls \"/Bulk/Whole genome sequences\" On DNAnexus, when a job is executed, a worker is spun up in the cloud, then the job's code and inputs are downloaded to that worker and exectuted. This is the standard behavior, but inputs can also be mounted to avoid their downloading costs.","title":"Genetic data"},{"location":"input/#plink2","text":"PLINK2 can read both BGEN and PLINK format. Therefore, we have 4 ways of inputing genetic data: File format Mounted BGEN No BGEN Yes PLINK No PLINK Yes After some trial and error, we have found that using the BGEN format without mounting it was the quickest way to perform a GWAS using PLINK2. Downloading and translating BGEN files locally was quicker than downloading or mounting the PLINK files. Therefore, in this tutorial, we will input BGEN files directly. The path to the genetic data is the following: \"/Bulk/Whole genome sequences/Population level genome variants, BGEN format - interim 200k release/\" .","title":"PLINK2"},{"location":"input/#additionnal-data","text":"In order to run our GWAS, apart from the genetic and sample data, we need 3 additionnal files: The phenotype (for instance, BMI) The ids of individuals we wish to keep (for instance, white british) The covariates to use (for instance, 18 genetic principal components, the sex and the age) Theses files can either be uploaded directly to your projects using dx upload , or created using DNAnexus data. This tutorial will guide you through the second option. All three files will be uploaded to your current dx repertory ( WKD_<your-name> if you are closely following this tutorial). If you want to upload them somewhere else, you can either move directory with dx cd before uploading, or use the --path or --destination option to specify the DNAnexus path to upload the files.","title":"Additionnal data"},{"location":"input/#phenotype","text":"To extract the phenotype that we want, we first need to download all available data-fields in our dataset. You will need the record-id , which is the id of the .dataset file at the root of your DNAnexus project. On your project's web page, you can find the id by selecting the .dataset file and searching for the ID in the info panel that appears on the right. Please note, when running the extract_dataset command you might encounter a ('Invalid JSON received from server', 200) error. If this happens, you simply need to rerun the code. dx extract_dataset <record-id> -ddd --delimiter \",\" This command will output 3 files: <app-id>.data_dictionary.csv contains a table with participants as the rows and metadata along the columns, including field names (see table below for naming convention) <app-id>.codings.csv contains a lookup table for the different medical codes, including ICD-10 codes that will be displayed in the diagnosis field column (p41270) <app-id>.entity_dictionary.csv contains the different entities that can be queried, where participant is the main entity that corresponds to most phenotype fields To make it easier, you can rename theses files to a shorter name like ukbb . rename <app-id> ukbb app* We first need to get the field name of the phenotype(s) we want to extract. As an example, we will extract the BMI index ( 21001 ), but you can extract any number of phenotypes. For the main participant phenotype entity, the Research Analysis Platform (UKB-RAP) uses field names with the following convention: Type of field Syntax for field name Example Neither instanced nor arrayed p<FIELD> p31 Instanced but not arrayed p<FIELD>_i<INSTANCE> p40005_i0 Arrayed but not instanced p<FIELD>_a<ARRAY> p41262_a0 Instanced and arrayed p<FIELD>_i<INSTANCE>_a<ARRAY> p93_i0_a0 This means one phenotype ID can actually have multiple data field. For example, BMI has four instances. The following python script will extract the phenotype that you wish, and every array or instance associated. It will ouptput pheno_extract.csv which contains individual ids and any phenotype you chose to extract. \"\"\" Extract phenotype(s) from UKBB based on field ID(s). \"\"\" import os import subprocess import pandas as pd # Input FILENAME = \"ukbb.dataset.data_dictionary.csv\" OUTPUT = \"pheno_extract.csv\" DATASET = \"<record-id>\" FIELD_ID = [21001] # BMI id def field_names_for_ids(filename, field_ids): \"\"\" Converts data-field id to corresponding field name. Parameters ---------- filename : str Path to the '.dataset.data_dictionary.csv' file. field_ids : list All field ids. data.frame (pandas) Projects's .data_dictionary.csv file. Returns ------- list All corresponding field names. \"\"\" data = pd.read_csv(filename, sep=',') field_names = [\"eid\"] for _id in field_ids: select = list(data[data.name.str.match(r'^p{}(_i\\d+)?(_a\\d+)?$'.format(_id))].name.values) field_names += select field_names = [f\"participant.{f}\" for f in field_names] return field_names # Convert id to names FIELD_NAMES = field_names_for_ids(FILENAME, FIELD_ID) FIELD_NAMES = \",\".join(FIELD_NAMES) # Extract phenotype(s) if os.path.exists(OUTPUT): os.remove(OUTPUT) cmd = [\"dx\", \"extract_dataset\", DATASET, \"--fields\", FIELD_NAMES, \"--delimiter\", \",\", \"--output\", OUTPUT] subprocess.check_call(cmd) Please be aware, since extract_dataset has no overwite option by design, we implemented ourselves. Running the previous code will first delete pheno_extract.csv if it's present, allowing for the extraction to happen. PLINK and regenie use the same formatting for the phenotype file, with a single exception : the code for missing values. Apart from this, both need to duplicate the individuals ids and only keep the first instance for our phenotype. More information on phenotype files formatting can be found here for PLINK2 and here for regenie. \"\"\" Format phenotype file. \"\"\" import pandas as pd # Input FILENAME = \"pheno_extract.csv\" PHENOTYPE = \"BMI\" SOFTWARE = 'p' # for PLINK2 or 'r' for regenie. def format_phenotype(filename, phenotype, software): \"\"\" Save phenotype according to software format. Parameters ---------- filename : str Phenotype file to format. phenotype : str Phenotype name. format : str { 'p', 'r'} Either 'p' for PLINK2 or 'r' for regenie, to correctly format the file. \"\"\" # Software specific format. if software == 'p': na_val = -9 output = f\"plink_{phenotype}.txt\" elif software == 'r': na_val = 'NA' output = f\"regenie_{phenotype}.txt\" # Data data = pd.read_csv(filename, sep=',') # To be changed accordingly pheno = data.iloc[:,[0,1]] pheno = pheno.rename(columns={pheno.columns[0]: \"IID\", pheno.columns[1]: phenotype}) data = data.rename(columns={data.columns[0]: \"FID\"}) merged = pd.concat([data.iloc[:, 0], pheno], axis=1) # Save output merged.to_csv(output, sep='\\t', index=False, header=True, na_rep=na_val) # Save phenotype format_phenotype(FILENAME, PHENOTYPE, SOFTWARE) You can modify the format_phenotype function to your heart's desire, depending on what you wish to do with the phenotypes. This is only a suggestion, and might not work for more specific phenotypes. You can now upload the formated phenotype file. dx upload plink_BMI.txt dx upload regenie_BMI.txt For the sake of this tutorial, we upload two files: one for each type of formatting.","title":"Phenotype"},{"location":"input/#individual-ids","text":"Running a GWAS on a specific population helps reduce the bias caused by population stratification. It is therefore an important step. To filter out individuals based on their ethnic background, we can use the phenotype extraction script and the data-field 21000 . You simply need to replace the following line: FIELD_ID = [21000] # ethnic background id This field uses the 1001 data encoding . In this code, 1001 means white british which is the main ethnic group, and the one we want to select. pop_code=1001 pop_name=\"white_british\" population=\"pheno_extract.csv\" awk -F \",\" -v var=\"$pop_code\" '$2~var{print $1,$1}' $population > $pop_name.txt This code will output the file white_british.txt , containing the ids of the individuals of the white british ethnic background. You can now upload the ids of your individuals. dx upload white_british.txt","title":"Individual ids"},{"location":"input/#covariates","text":"The genetic principal components from the UKBB individuals are stored in the 22009 data field. We could use our phenotype extraction algorithm, but for some reason, it is not working. Therefore, we will use another script. We will use 20 variables as covariates: the first 18 PCA components, the sex ( 31 ) and the age ( 21003 ) of individuals. However, you can extract whatever you want as covariates. More information on covariates files formatting can be found here for PLINK2 and here for regenie. record_id=\"<record-id>\" field_names=\"participant.eid,participant.eid,\" for i in {1..18} do field_names+=\"participant.p22009_a$i,\" done field_names+=\"participant.p31,participant.p21003_i0\" # Sex and age dx extract_dataset $record_id --fields $field_names --delimiter \",\" --output covariates.txt echo -e \"FID,IID,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,PC17,PC18,Sex,Age\" > file.tmp tail -n+2 covariates.txt >> file.tmp awk -F , '$3!=\"\"' file.tmp > covariates.txt # Remove ind with no PC data sed 's/,/\\t/g' covariates.txt > file.tmp mv file.tmp covariates.txt You can now upload the covariates file. dx upload covariates.txt","title":"Covariates"},{"location":"plink/","text":"Using PLINK2 Input files Before running a GWAS on DNAnexus using PLINK2, you need to make sure you have these 3 files uploaded to DNAnexus: The phenotype: plink_BMI.txt The ids of individuals we wish to keep: white british.txt The covariates to use: covariates.txt You can check their presence with the following command: dx ls Please refer to the Input files section if you don't have these files. Running a GWAS On DNAnexus, PLINK2 is available as part of the Swiss Army Knife app . We choose to use the same instance for all GWASs, to simplify the code, but this can be changed to your liking. Same for the priority and the cost limit. Quality control We perform the QC at the same time as our GWAS. The variants are filtered using following options: --maf 0.0001 --hwe 1e-50 --geno 0.1 --mind 0.1 Please change the thresholds according to your preferences. Linear or logistic regression pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/plink_$pheno.txt\" ind_path=\"/WKD_<your-name>/white_british.txt\" ind=$(basename \"$ind_path\") cov_path=\"/WKD_<your-name>/covariates.txt\" cov=$(basename \"$cov_path\") instance=\"mem2_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p plink_gwas_$pheno for chr_num in $(seq 1 22); do prefix=\"/Bulk/Whole genome sequences/Population level genome variants, BGEN format - interim 200k release//ukb24306_c${chr_num}_b0_v1\" bgen=$(basename \"$prefix\") plink_command=\"plink2 \\ --threads $threads \\ --maf 0.0001 \\ --hwe 1e-50 \\ --geno 0.1 \\ --mind 0.1 \\ --glm \\ --keep $ind \\ --covar $cov \\ --covar-name PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,PC17,PC18,Age,Sex \\ --pheno plink_$pheno.txt \\ --bgen $bgen.bgen ref-first \\ --sample $bgen.sample \\ --no-psam-pheno \\ --out gwas_$pheno/sumstat_c${chr_num}\" dx run swiss-army-knife \\ --priority \"$priority\" --cost-limit \"$cost_limit\" \\ -icmd=\"$plink_command\" \\ --instance-type \"$instance\" \\ --name=\"p_gwas_${pheno}_c${chr_num}\" \\ -iin=\"$ind_path\" \\ -iin=\"$cov_path\" \\ -iin=\"$pheno_path\" \\ -iin=\"$prefix.sample\" \\ -iin=\"$prefix.bgen\" \\ -y done dx cd ../ This script will create a new directory named plink_gwas_<phenotype> in the project on DNAnexus. In this folder, you will find a total of 44 files, named sumstat_c<num> (two per chromosome, the summary statistics and the log). Computing the results Now that all of the summary statistics are computed, we can clean them up and combine them into one clean file. We will create a new directory named plink_gwas_<phenotype> , locally this time, with inside another directory named statistics containing all of the summary statistics per chromosome. The combination of all of them will be located at the same level than statistics , making it easier to find. pheno=\"BMI\" type=\"linear\" # to change accordingly output_path=\"plink_gwas_$pheno\" stat_path=\"$output_path/statistics\" mkdir -p $output_path mkdir -p $stat_path for chr_num in $(seq 1 22); do result=\"sumstat_c${chr_num}.$pheno.glm.$type\" dx download \"gwas_$pheno/$result\" -o $stat_path if [ $chr_num -eq 1 ]; then head -n1 \"$stat_path/$result\" > \"$output_path/sumstat_${pheno}.ADD\" fi head -n1 \"$stat_path/$result\" > \"$stat_path/sumstat_c${chr_num}.ADD\" grep \"ADD\" \"$stat_path/$result\" >> \"$stat_path/sumstat_c${chr_num}.ADD\" grep \"ADD\" \"$stat_path/$result\" >> \"$output_path/sumstat_${pheno}.ADD\" done Congratulations, you have successfully completed a GWAS using PLINK2 on DNAnexus!","title":"Using PLINK2"},{"location":"plink/#using-plink2","text":"","title":"Using PLINK2"},{"location":"plink/#input-files","text":"Before running a GWAS on DNAnexus using PLINK2, you need to make sure you have these 3 files uploaded to DNAnexus: The phenotype: plink_BMI.txt The ids of individuals we wish to keep: white british.txt The covariates to use: covariates.txt You can check their presence with the following command: dx ls Please refer to the Input files section if you don't have these files.","title":"Input files"},{"location":"plink/#running-a-gwas","text":"On DNAnexus, PLINK2 is available as part of the Swiss Army Knife app . We choose to use the same instance for all GWASs, to simplify the code, but this can be changed to your liking. Same for the priority and the cost limit.","title":"Running a GWAS"},{"location":"plink/#quality-control","text":"We perform the QC at the same time as our GWAS. The variants are filtered using following options: --maf 0.0001 --hwe 1e-50 --geno 0.1 --mind 0.1 Please change the thresholds according to your preferences.","title":"Quality control"},{"location":"plink/#linear-or-logistic-regression","text":"pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/plink_$pheno.txt\" ind_path=\"/WKD_<your-name>/white_british.txt\" ind=$(basename \"$ind_path\") cov_path=\"/WKD_<your-name>/covariates.txt\" cov=$(basename \"$cov_path\") instance=\"mem2_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p plink_gwas_$pheno for chr_num in $(seq 1 22); do prefix=\"/Bulk/Whole genome sequences/Population level genome variants, BGEN format - interim 200k release//ukb24306_c${chr_num}_b0_v1\" bgen=$(basename \"$prefix\") plink_command=\"plink2 \\ --threads $threads \\ --maf 0.0001 \\ --hwe 1e-50 \\ --geno 0.1 \\ --mind 0.1 \\ --glm \\ --keep $ind \\ --covar $cov \\ --covar-name PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,PC17,PC18,Age,Sex \\ --pheno plink_$pheno.txt \\ --bgen $bgen.bgen ref-first \\ --sample $bgen.sample \\ --no-psam-pheno \\ --out gwas_$pheno/sumstat_c${chr_num}\" dx run swiss-army-knife \\ --priority \"$priority\" --cost-limit \"$cost_limit\" \\ -icmd=\"$plink_command\" \\ --instance-type \"$instance\" \\ --name=\"p_gwas_${pheno}_c${chr_num}\" \\ -iin=\"$ind_path\" \\ -iin=\"$cov_path\" \\ -iin=\"$pheno_path\" \\ -iin=\"$prefix.sample\" \\ -iin=\"$prefix.bgen\" \\ -y done dx cd ../ This script will create a new directory named plink_gwas_<phenotype> in the project on DNAnexus. In this folder, you will find a total of 44 files, named sumstat_c<num> (two per chromosome, the summary statistics and the log).","title":"Linear or logistic regression"},{"location":"plink/#computing-the-results","text":"Now that all of the summary statistics are computed, we can clean them up and combine them into one clean file. We will create a new directory named plink_gwas_<phenotype> , locally this time, with inside another directory named statistics containing all of the summary statistics per chromosome. The combination of all of them will be located at the same level than statistics , making it easier to find. pheno=\"BMI\" type=\"linear\" # to change accordingly output_path=\"plink_gwas_$pheno\" stat_path=\"$output_path/statistics\" mkdir -p $output_path mkdir -p $stat_path for chr_num in $(seq 1 22); do result=\"sumstat_c${chr_num}.$pheno.glm.$type\" dx download \"gwas_$pheno/$result\" -o $stat_path if [ $chr_num -eq 1 ]; then head -n1 \"$stat_path/$result\" > \"$output_path/sumstat_${pheno}.ADD\" fi head -n1 \"$stat_path/$result\" > \"$stat_path/sumstat_c${chr_num}.ADD\" grep \"ADD\" \"$stat_path/$result\" >> \"$stat_path/sumstat_c${chr_num}.ADD\" grep \"ADD\" \"$stat_path/$result\" >> \"$output_path/sumstat_${pheno}.ADD\" done Congratulations, you have successfully completed a GWAS using PLINK2 on DNAnexus!","title":"Computing the results"},{"location":"regenie/","text":"Using regenie Input files Before running a GWAS on DNAnexus using PLINK2, you need to make sure you have these 3 files uploaded to DNAnexus: The phenotype: regenie_BMI.txt The ids of individuals we wish to keep: white british.txt The covariates to use: covariates.txt You can check their presence with the following command: dx ls Please refer to the Input files section if you don't have these files. Running a GWAS On DNAnexus, regenie is available either as part of the Swiss Army Knife app ( swiss-army-knife ) or as its own app called app-regenie . We choose to use the same instance for all GWASs, to simplify the code, but this can be changed to your liking. Same for the priority and the cost limit. Quality control Unlike with PLINK2, we cannot perform the QC at the same time as our GWAS, we must do it before hand. The variants are filtered using following options: --maf 0.0001 --hwe 1e-50 --geno 0.1 --mind 0.1 Please change the thresholds according to your preferences. For each chromosome, we will compute two files: A list of SNPs that pass QC: QC_pass_c<chrom-number>.snplist A list of sample IDs that pass QC: QC_pass_c<chrom-number>.id They will be stored into another directory called QC_lists to avoid crowding the main repertory for the GWAS. pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" ind_path=\"/WKD_<your-name>/white_british.txt\" ind=$(basename \"$ind_path\") instance=\"mem1_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno dx mkdir -p QC_lists dx cd QC_lists for chr_num in $(seq 22 22); do prefix=\"/Bulk/Whole genome sequences/Population level genome variants, BGEN format - interim 200k release//ukb24306_c${chr_num}_b0_v1\" bgen=$(basename \"$prefix\") plink_command=\"plink2 \\ --threads $threads \\ --maf 0.0001 \\ --hwe 1e-50 \\ --geno 0.1 \\ --mind 0.1 \\ --write-snplist \\ --write-samples \\ --no-id-header \\ --keep $ind \\ --bgen $bgen.bgen ref-first \\ --sample $bgen.sample \\ --pheno regenie_$pheno.txt \\ --no-psam-pheno \\ --out QC_pass_c${chr_num}\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$plink_command\" \\ --instance-type $instance \\ --name=\"reg_QC_${pheno}_c${chr_num}\" \\ -iin=\"$ind_path\" \\ -iin=\"$pheno_path\" \\ -iin=\"$prefix.sample\" \\ -iin=\"$prefix.bgen\" \\ -y done dx cd ../../ This is in preparation for running Step 2 . Step 0: Merging files Before running our GWAS using regenie, we first need to merge all of the genotype call files (chromosome 1 to 22) into one file. This is in preparation for running Step 1 . instance=\"mem1_ssd1_v2_x16\" threads=16 pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" # not strictly needed, but swiss-army-knife needs at least one input geno_array=\"/mnt/project/Bulk/Genotype\\ Results/Genotype\\ calls/ukb22418_c[1-9]*\" dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno dx mkdir -p merge dx cd merge merge_cmd=\"cp $geno_array . ; \\ ls *.bed | sed -e 's/.bed//g' > files_to_merge.txt; \\ plink --threads $threads \\ --merge-list files_to_merge.txt --make-bed \\ --autosome --out c1_c22_merged; \\ rm files_to_merge.txt;\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$merge_cmd\" \\ --instance-type $instance \\ --name=\"${pheno}_step0\" \\ --tag=\"Step 0\" \\ -iin=\"$pheno_path\" \\ -y dx cd ../../ Like in the QC step , we need to save both the list of SNPs ( QC_pass_geno_array.snplist ) and the list of sample IDs ( QC_pass_geno_array.id ) that pass QC for our array genotype data. pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" ind_path=\"/WKD_<your-name>/white_british.txt\" ind=$(basename \"$ind_path\") merge_path=\"/WKD_<your-name>/regenie_gwas_$pheno/merge/c1_c22_merged\" merge=$(basename \"$merge_path\") instance=\"mem1_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno dx mkdir -p merge dx cd merge plink_command=\"plink2 \\ --threads $threads \\ --maf 0.0001 \\ --hwe 1e-50 \\ --geno 0.1 \\ --mind 0.1 \\ --write-snplist \\ --write-samples \\ --no-id-header \\ --keep $ind \\ --bfile $merged \\ --pheno regenie_$pheno.txt \\ --no-psam-pheno \\ --out QC_pass_geno_array\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$plink_command\" \\ --instance-type $instance \\ --name=\"reg_QC_${pheno}_merged\" \\ -iin=\"$ind_path\" \\ -iin=\"$pheno_path\" \\ -iin=\"$merge_path.bed\" \\ -iin=\"$merge_path.bim\" \\ -iin=\"$merge_path.fam\" \\ -y dx cd ../../ Step 1: Estimate SNPs contribution The first step of a regenie GWAS is the estimation of how background SNPs contribute to the phenotype. During this step, a subset of genetic markers are used to fit a whole genome regression model that captures a good fraction of the phenotype variance attributable to genetic effects ( regenie official documentation ). pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" ind_path=\"/WKD_<your-name>/white_british.txt\" ind=$(basename \"$ind_path\") cov_path=\"/WKD_<your-name>/covariates.txt\" cov=$(basename \"$cov_path\") merge_path=\"/WKD_<your-name>/regenie_gwas_$pheno/merge/c1_c22_merged\" merge=$(basename \"$merge_path\") QC_path=\"/WKD_<your-name>regenie_gwas_$pheno/merge/QC_pass_geno_array\" QC=$(basename \"$QC_path\") instance=\"mem1_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno dx mkdir -p merge dx cd merge regenie_command=\"regenie \\ --threads $threads \\ --step 1 \\ --bsize 1000 \\ --loocv \\ --gz \\ --extract $QC$.snplist \\ --keep $QC.id \\ --bed $merge \\ --phenoFile regenie_$pheno.txt \\ --phenoCol $pheno \\ --covarFile $cov \\ --covarCol Sex \\ --covarCol Age \\ --covarCol PC{1:18} \\ --out ${pheno}_step1\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$regenie_command\" \\ --instance-type $instance \\ --name=\"${pheno}_step1\" \\ --tag=\"Step 1\" \\ -iin=\"$ind_path\" \\ -iin=\"$pheno_path\" \\ -iin=\"$cov_path\" \\ -iin=\"$merge_path.bed\" \\ -iin=\"$merge_path.bim\" \\ -iin=\"$merge_path.fam\" \\ -iin=\"$QC_path.snplist\" \\ -iin=\"$QC_path.id\" \\ -y dx cd ../../ Please note, when using a binary phenotype you need to add the --bt option to the regenie command. Step 2: Linear or logistic regression The second step of a regenie GWAS is the regression. During this step, whole genome markers are tested for association with the phenotype conditional upon the prediction from the regression model in Step 1 ( regenie official documentation ). pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" cov_path=\"/WKD_<your-name>/covariates.txt\" cov=$(basename \"$cov_path\") pred_path=\"/WKD_<your-name>/regenie_gwas_$pheno/merge/${pheno}_pred.list\" pred=$(basename \"$pred_path\") instance=\"mem1_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno for chr_num in $(seq 22 22); do prefix=\"/Bulk/Whole genome sequences/Population level genome variants, BGEN format - interim 200k release//ukb24306_c${chr_num}_b0_v1\" bgen=$(basename \"$prefix\") QC_path=\"/WKD_<your-name>/regenie_gwas_$pheno/QC_lists/QC_pass_c${chr_num}\" QC=$(basename \"$QC_path\") regenie_command=\"regenie \\ --threads $threads \\ --step 2 \\ --bsize 200 \\ --approx \\ --firth-se \\ --firth \\ --gz \\ --pred $pred \\ --extract $QC.snplist \\ --keep $QC.id \\ --bgen $bgen.bgen ref-first \\ --sample $bgen.sample \\ --phenoFile regenie_$pheno.txt \\ --phenoCol $pheno \\ --covarFile $cov \\ --covarCol Sex \\ --covarCol Age \\ --covarCol PC{1:18} \\ --out sumstat_c${chr_num}\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$regenie_command\" \\ --instance-type $instance \\ --name=\"gwas_${pheno}_step2\" \\ --tag=\"Step 2\" \\ -iin=\"$pheno_path\" \\ -iin=\"$cov_path\" \\ -iin=\"$pred_path\" \\ -iin=\"$prefix.sample\" \\ -iin=\"$prefix.bgen\" \\ -iin=\"$QC_path.snplist\" \\ -iin=\"$QC_path.id\" \\ -y done dx cd ../../ Please note, when using a binary phenotype you need to add the --bt option to the regenie command. This script will create a new directory named regenie_gwas_<phenotype> in the project on DNAnexus. In this folder, you will find a total of 44 files, named sumstat_c<num> (two per chromosome, the summary statistics and the log). Computing the results Now that all of the summary statistics are computed, we can clean them up and combine them into one clean file. We will create a new directory named regenie_gwas_<phenotype> , locally this time, with inside another directory named statistics containing all of the summary statistics per chromosome. The combination of all of them will be located at the same level than statistics , making it easier to find. pheno=\"BMI\" type=\"linear\" # to change accordingly output_path=\"regenie_gwas_$pheno\" stat_path=\"$output_path/statistics\" mkdir -p $output_path mkdir -p $stat_path for chr_num in $(seq 1 22); do result=\"sumstat_c${chr_num}.$pheno.glm.$type\" dx download \"gwas_$pheno/$result\" -o $stat_path if [ $chr_num -eq 1 ]; then head -n1 \"$stat_path/$result\" > \"$output_path/sumstat_${pheno}.ADD\" fi head -n1 \"$stat_path/$result\" > \"$stat_path/sumstat_c${chr_num}.ADD\" grep \"ADD\" \"$stat_path/$result\" >> \"$stat_path/sumstat_c${chr_num}.ADD\" grep \"ADD\" \"$stat_path/$result\" >> \"$output_path/sumstat_${pheno}.ADD\" done Congratulations, you have successfully completed a GWAS using regenie on DNAnexus!","title":"Using regenie"},{"location":"regenie/#using-regenie","text":"","title":"Using regenie"},{"location":"regenie/#input-files","text":"Before running a GWAS on DNAnexus using PLINK2, you need to make sure you have these 3 files uploaded to DNAnexus: The phenotype: regenie_BMI.txt The ids of individuals we wish to keep: white british.txt The covariates to use: covariates.txt You can check their presence with the following command: dx ls Please refer to the Input files section if you don't have these files.","title":"Input files"},{"location":"regenie/#running-a-gwas","text":"On DNAnexus, regenie is available either as part of the Swiss Army Knife app ( swiss-army-knife ) or as its own app called app-regenie . We choose to use the same instance for all GWASs, to simplify the code, but this can be changed to your liking. Same for the priority and the cost limit.","title":"Running a GWAS"},{"location":"regenie/#quality-control","text":"Unlike with PLINK2, we cannot perform the QC at the same time as our GWAS, we must do it before hand. The variants are filtered using following options: --maf 0.0001 --hwe 1e-50 --geno 0.1 --mind 0.1 Please change the thresholds according to your preferences. For each chromosome, we will compute two files: A list of SNPs that pass QC: QC_pass_c<chrom-number>.snplist A list of sample IDs that pass QC: QC_pass_c<chrom-number>.id They will be stored into another directory called QC_lists to avoid crowding the main repertory for the GWAS. pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" ind_path=\"/WKD_<your-name>/white_british.txt\" ind=$(basename \"$ind_path\") instance=\"mem1_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno dx mkdir -p QC_lists dx cd QC_lists for chr_num in $(seq 22 22); do prefix=\"/Bulk/Whole genome sequences/Population level genome variants, BGEN format - interim 200k release//ukb24306_c${chr_num}_b0_v1\" bgen=$(basename \"$prefix\") plink_command=\"plink2 \\ --threads $threads \\ --maf 0.0001 \\ --hwe 1e-50 \\ --geno 0.1 \\ --mind 0.1 \\ --write-snplist \\ --write-samples \\ --no-id-header \\ --keep $ind \\ --bgen $bgen.bgen ref-first \\ --sample $bgen.sample \\ --pheno regenie_$pheno.txt \\ --no-psam-pheno \\ --out QC_pass_c${chr_num}\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$plink_command\" \\ --instance-type $instance \\ --name=\"reg_QC_${pheno}_c${chr_num}\" \\ -iin=\"$ind_path\" \\ -iin=\"$pheno_path\" \\ -iin=\"$prefix.sample\" \\ -iin=\"$prefix.bgen\" \\ -y done dx cd ../../ This is in preparation for running Step 2 .","title":"Quality control"},{"location":"regenie/#step-0-merging-files","text":"Before running our GWAS using regenie, we first need to merge all of the genotype call files (chromosome 1 to 22) into one file. This is in preparation for running Step 1 . instance=\"mem1_ssd1_v2_x16\" threads=16 pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" # not strictly needed, but swiss-army-knife needs at least one input geno_array=\"/mnt/project/Bulk/Genotype\\ Results/Genotype\\ calls/ukb22418_c[1-9]*\" dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno dx mkdir -p merge dx cd merge merge_cmd=\"cp $geno_array . ; \\ ls *.bed | sed -e 's/.bed//g' > files_to_merge.txt; \\ plink --threads $threads \\ --merge-list files_to_merge.txt --make-bed \\ --autosome --out c1_c22_merged; \\ rm files_to_merge.txt;\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$merge_cmd\" \\ --instance-type $instance \\ --name=\"${pheno}_step0\" \\ --tag=\"Step 0\" \\ -iin=\"$pheno_path\" \\ -y dx cd ../../ Like in the QC step , we need to save both the list of SNPs ( QC_pass_geno_array.snplist ) and the list of sample IDs ( QC_pass_geno_array.id ) that pass QC for our array genotype data. pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" ind_path=\"/WKD_<your-name>/white_british.txt\" ind=$(basename \"$ind_path\") merge_path=\"/WKD_<your-name>/regenie_gwas_$pheno/merge/c1_c22_merged\" merge=$(basename \"$merge_path\") instance=\"mem1_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno dx mkdir -p merge dx cd merge plink_command=\"plink2 \\ --threads $threads \\ --maf 0.0001 \\ --hwe 1e-50 \\ --geno 0.1 \\ --mind 0.1 \\ --write-snplist \\ --write-samples \\ --no-id-header \\ --keep $ind \\ --bfile $merged \\ --pheno regenie_$pheno.txt \\ --no-psam-pheno \\ --out QC_pass_geno_array\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$plink_command\" \\ --instance-type $instance \\ --name=\"reg_QC_${pheno}_merged\" \\ -iin=\"$ind_path\" \\ -iin=\"$pheno_path\" \\ -iin=\"$merge_path.bed\" \\ -iin=\"$merge_path.bim\" \\ -iin=\"$merge_path.fam\" \\ -y dx cd ../../","title":"Step 0: Merging files"},{"location":"regenie/#step-1-estimate-snps-contribution","text":"The first step of a regenie GWAS is the estimation of how background SNPs contribute to the phenotype. During this step, a subset of genetic markers are used to fit a whole genome regression model that captures a good fraction of the phenotype variance attributable to genetic effects ( regenie official documentation ). pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" ind_path=\"/WKD_<your-name>/white_british.txt\" ind=$(basename \"$ind_path\") cov_path=\"/WKD_<your-name>/covariates.txt\" cov=$(basename \"$cov_path\") merge_path=\"/WKD_<your-name>/regenie_gwas_$pheno/merge/c1_c22_merged\" merge=$(basename \"$merge_path\") QC_path=\"/WKD_<your-name>regenie_gwas_$pheno/merge/QC_pass_geno_array\" QC=$(basename \"$QC_path\") instance=\"mem1_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno dx mkdir -p merge dx cd merge regenie_command=\"regenie \\ --threads $threads \\ --step 1 \\ --bsize 1000 \\ --loocv \\ --gz \\ --extract $QC$.snplist \\ --keep $QC.id \\ --bed $merge \\ --phenoFile regenie_$pheno.txt \\ --phenoCol $pheno \\ --covarFile $cov \\ --covarCol Sex \\ --covarCol Age \\ --covarCol PC{1:18} \\ --out ${pheno}_step1\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$regenie_command\" \\ --instance-type $instance \\ --name=\"${pheno}_step1\" \\ --tag=\"Step 1\" \\ -iin=\"$ind_path\" \\ -iin=\"$pheno_path\" \\ -iin=\"$cov_path\" \\ -iin=\"$merge_path.bed\" \\ -iin=\"$merge_path.bim\" \\ -iin=\"$merge_path.fam\" \\ -iin=\"$QC_path.snplist\" \\ -iin=\"$QC_path.id\" \\ -y dx cd ../../ Please note, when using a binary phenotype you need to add the --bt option to the regenie command.","title":"Step 1: Estimate SNPs contribution"},{"location":"regenie/#step-2-linear-or-logistic-regression","text":"The second step of a regenie GWAS is the regression. During this step, whole genome markers are tested for association with the phenotype conditional upon the prediction from the regression model in Step 1 ( regenie official documentation ). pheno=\"BMI\" pheno_path=\"/WKD_<your-name>/regenie_$pheno.txt\" cov_path=\"/WKD_<your-name>/covariates.txt\" cov=$(basename \"$cov_path\") pred_path=\"/WKD_<your-name>/regenie_gwas_$pheno/merge/${pheno}_pred.list\" pred=$(basename \"$pred_path\") instance=\"mem1_ssd1_v2_x16\" threads=16 priority=\"low\" cost_limit=3 dx mkdir -p regenie_gwas_$pheno dx cd regenie_gwas_$pheno for chr_num in $(seq 22 22); do prefix=\"/Bulk/Whole genome sequences/Population level genome variants, BGEN format - interim 200k release//ukb24306_c${chr_num}_b0_v1\" bgen=$(basename \"$prefix\") QC_path=\"/WKD_<your-name>/regenie_gwas_$pheno/QC_lists/QC_pass_c${chr_num}\" QC=$(basename \"$QC_path\") regenie_command=\"regenie \\ --threads $threads \\ --step 2 \\ --bsize 200 \\ --approx \\ --firth-se \\ --firth \\ --gz \\ --pred $pred \\ --extract $QC.snplist \\ --keep $QC.id \\ --bgen $bgen.bgen ref-first \\ --sample $bgen.sample \\ --phenoFile regenie_$pheno.txt \\ --phenoCol $pheno \\ --covarFile $cov \\ --covarCol Sex \\ --covarCol Age \\ --covarCol PC{1:18} \\ --out sumstat_c${chr_num}\" dx run swiss-army-knife \\ --priority low --cost-limit 3 \\ -icmd=\"$regenie_command\" \\ --instance-type $instance \\ --name=\"gwas_${pheno}_step2\" \\ --tag=\"Step 2\" \\ -iin=\"$pheno_path\" \\ -iin=\"$cov_path\" \\ -iin=\"$pred_path\" \\ -iin=\"$prefix.sample\" \\ -iin=\"$prefix.bgen\" \\ -iin=\"$QC_path.snplist\" \\ -iin=\"$QC_path.id\" \\ -y done dx cd ../../ Please note, when using a binary phenotype you need to add the --bt option to the regenie command. This script will create a new directory named regenie_gwas_<phenotype> in the project on DNAnexus. In this folder, you will find a total of 44 files, named sumstat_c<num> (two per chromosome, the summary statistics and the log).","title":"Step 2: Linear or logistic regression"},{"location":"regenie/#computing-the-results","text":"Now that all of the summary statistics are computed, we can clean them up and combine them into one clean file. We will create a new directory named regenie_gwas_<phenotype> , locally this time, with inside another directory named statistics containing all of the summary statistics per chromosome. The combination of all of them will be located at the same level than statistics , making it easier to find. pheno=\"BMI\" type=\"linear\" # to change accordingly output_path=\"regenie_gwas_$pheno\" stat_path=\"$output_path/statistics\" mkdir -p $output_path mkdir -p $stat_path for chr_num in $(seq 1 22); do result=\"sumstat_c${chr_num}.$pheno.glm.$type\" dx download \"gwas_$pheno/$result\" -o $stat_path if [ $chr_num -eq 1 ]; then head -n1 \"$stat_path/$result\" > \"$output_path/sumstat_${pheno}.ADD\" fi head -n1 \"$stat_path/$result\" > \"$stat_path/sumstat_c${chr_num}.ADD\" grep \"ADD\" \"$stat_path/$result\" >> \"$stat_path/sumstat_c${chr_num}.ADD\" grep \"ADD\" \"$stat_path/$result\" >> \"$output_path/sumstat_${pheno}.ADD\" done Congratulations, you have successfully completed a GWAS using regenie on DNAnexus!","title":"Computing the results"},{"location":"setup/","text":"Initial setup In order to connect to DNAnexus remotely, you first need to install the dxpy package. pip3 install dxpy To enable tab completion, run the following command, or add it to your .bashrc : eval \"$(register-python-argcomplete dx|sed 's/-o default//')\" You can now enter your DNAnexus credentials to access your project remotely by using the following command: dx login Your authentication token and your current project settings have now been saved in a local configuration file, and you're ready to start accessing your project. By default, your information expires in 30 days, but this can be changed using the --timeout option. For instance, if you want your info to expire in 6 months , use the following command. The -help option is useful if you want to know more about the --timeout input format. dx login --timeout 6M By default, any job prompted here will output in your current DNAnexus repertory. Therefore, you can create a new folder and move into it, to help keep your project tidy (especially if multiple people use it). dx mkdir WKD_<your-name> dx cd WKD_<your-name> It goes without saying that you can name this repertory however you want. Now, all job will output in this repertory. You can find the documentation for all dx commands we will use here .","title":"Initial setup"},{"location":"setup/#initial-setup","text":"In order to connect to DNAnexus remotely, you first need to install the dxpy package. pip3 install dxpy To enable tab completion, run the following command, or add it to your .bashrc : eval \"$(register-python-argcomplete dx|sed 's/-o default//')\" You can now enter your DNAnexus credentials to access your project remotely by using the following command: dx login Your authentication token and your current project settings have now been saved in a local configuration file, and you're ready to start accessing your project. By default, your information expires in 30 days, but this can be changed using the --timeout option. For instance, if you want your info to expire in 6 months , use the following command. The -help option is useful if you want to know more about the --timeout input format. dx login --timeout 6M By default, any job prompted here will output in your current DNAnexus repertory. Therefore, you can create a new folder and move into it, to help keep your project tidy (especially if multiple people use it). dx mkdir WKD_<your-name> dx cd WKD_<your-name> It goes without saying that you can name this repertory however you want. Now, all job will output in this repertory. You can find the documentation for all dx commands we will use here .","title":"Initial setup"}]}